{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"ОбрЛабДан.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohYRxpup2oi9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwbTEcOzQX0q"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQi-_RUqzFp3"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import datetime\n",
        "from matplotlib import mlab\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import BoundaryNorm\n",
        "from matplotlib.ticker import MaxNLocator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdeo50EhzJ6R"
      },
      "source": [
        "class LabProcessing():\n",
        "  \"\"\"Класс для обработки лабораторных данных\"\"\"\n",
        "  \n",
        "  def rename_files(self, txt_list):\n",
        "    \"\"\"Переименовывает файлы HFP.txt по порядку 1-5\"\"\"\n",
        "    txt_list.sort()\n",
        "    new_list = []\n",
        "    i = 1\n",
        "    for file in txt_list:\n",
        "      match = re.search(r'\\d\\d\\d\\d\\D\\w\\w\\w\\d', file)[0]\n",
        "      file_split = file.split(match)\n",
        "      match2 = re.search(r'\\d\\d\\d\\d\\D\\w\\w\\w', match)[0]\n",
        "      new_list.append(file_split[0] + match2 + str(i) + file_split[1])\n",
        "      i += 1\n",
        "\n",
        "    l = 0\n",
        "    while (l < len(txt_list)):\n",
        "      os.rename(txt_list[l], new_list[l])\n",
        "      l += 1\n",
        "\n",
        "  def run_panel(self, path_folder, path_dist, list_of_sens):\n",
        "      for k in list_of_sens:\n",
        "          file = k\n",
        "          open_data = os.path.join(path_folder, 'df_' + file + '.pkl')\n",
        "          print(open_data)\n",
        "          df_garm_bd = pd.read_pickle(r'{}'.format(open_data))\n",
        "          l = {}\n",
        "          print(len(df_garm_bd))\n",
        "          for k in range(len(df_garm_bd)):\n",
        "              if df_garm_bd.iloc[k][0] not in l:\n",
        "                  l.update({df_garm_bd.iloc[k][0]: df_garm_bd.iloc[k][2]})\n",
        "              if df_garm_bd.iloc[k][0] in l:\n",
        "                  s = l[df_garm_bd.iloc[k][0]]\n",
        "                  s = np.vstack((s, df_garm_bd.iloc[k][2]))\n",
        "                  l.update({df_garm_bd.iloc[k][0]: s})\n",
        "        \n",
        "          for k, v in l.items():\n",
        "              l.update({k: np.median(v, axis=0)})\n",
        "          #a = input('Задать глубину построения?(1/0)')\n",
        "          a = '0'\n",
        "          if a == '1':\n",
        "              b = input('Введите интервал(например: 25 30): ')\n",
        "              bb = [int(k) for k in b.split(' ')]\n",
        "              l_wit = {}\n",
        "              for key, value in l.items():\n",
        "                  if bb[0] < float(key) < bb[1]:\n",
        "                      l_wit.update({key: value})\n",
        "              l = l_wit\n",
        "          else:\n",
        "              pass\n",
        "\n",
        "          print('Строиться панель задержек')\n",
        "          \"\"\"\n",
        "          z_arr = []\n",
        "          for k in l.values():\n",
        "              z = []\n",
        "              for kl in k:\n",
        "                  #print(kl, type(kl))\n",
        "                  if kl == np.array(0):\n",
        "                      z_log = 1\n",
        "                  else:\n",
        "                      z_log = 20 * np.log10(kl)\n",
        "                  z.append(z_log)\n",
        "              z_arr.append(np.array(z))\n",
        "              \"\"\"\n",
        "      \n",
        "          z = np.array([k for k in l.values()])\n",
        "          y = (np.array([sorted([round(float(k), 2) for k in list(l.keys())], reverse=True)] * 2047)).transpose()\n",
        "          x = np.array([[k for k in range(-1023, 1024)]] * len(y))\n",
        "          print(len(x), len(x[0]), len(y), len(y[0]))\n",
        "          z = z[:-1, :-1]\n",
        "          levels = MaxNLocator(nbins=500).tick_values(0, 1)\n",
        "          cmap = plt.get_cmap('Spectral_r', 100)\n",
        "          norm = BoundaryNorm(levels, ncolors=cmap.N, clip=True)\n",
        "\n",
        "          fig, ax0 = plt.subplots(figsize=(20, 10))\n",
        "          im = ax0.pcolormesh(x, y, z/z.max(), cmap=cmap, norm=norm)\n",
        "          fig.colorbar(im, ax=ax0)\n",
        "          ax0.set_title(f'Панель задержек между дачтиками {file}')\n",
        "          ax0.set_xlabel('Высота', fontsize = 20)\n",
        "          ax0.set_ylabel('Задержка', fontsize = 20)\n",
        "          # cf = ax1.contourf(x[:-1, :-1], y[:-1, :-1], z, levels=levels, cmap=cmap)\n",
        "          # fig.colorbar(cf, ax=ax1)\n",
        "          # ax1.set_title('contourf with levels')\n",
        "          # fig.tight_layout()\n",
        "          save_fig = os.path.join(path_dist, 'panel' + file + '.png')\n",
        "          plt.savefig(save_fig)\n",
        "          plt.close(fig)\n",
        "\n",
        "  def run_superbase(self, file_list, path_dist):\n",
        "    print('Создается база. Подождите...')\n",
        "    max_value = 2**15\n",
        "    deep_list = []\n",
        "    time_series_list = []\n",
        "    for file in file_list:\n",
        "      with open(file, 'r') as f:\n",
        "        linel = [line.split(' ') for line in [line.rstrip() for line in f] if len(line) != 0][1:]\n",
        "        linel_withoutdeep = np.array([k[1:] for k in linel], dtype = float)\n",
        "        linel_withoutdeep[linel_withoutdeep == 0] = 1 \n",
        "        linel_withoutdeep = 20*np.nan_to_num(np.log10(linel_withoutdeep/max_value))\n",
        "        deep_list.append([k[0] for k in linel[1:]])\n",
        "        time_series_list.append(linel_withoutdeep)\n",
        "\n",
        "    superbase = []\n",
        "    deep_list_array = np.array(deep_list, dtype = np.float16)\n",
        "    i = 0\n",
        "    for k in deep_list_array[0]:\n",
        "          superbase.append(\n",
        "              [k, \n",
        "                time_series_list[0][i], \n",
        "                time_series_list[1][i], \n",
        "                time_series_list[2][i], \n",
        "                time_series_list[3][i], \n",
        "                time_series_list[4][i], \n",
        "                time_series_list[5][i]\n",
        "              ]\n",
        "          )\n",
        "          i += 1\n",
        "    if not os.path.exists(path_dist):\n",
        "      os.makedirs(path_dist)\n",
        "    df_superbase = pd.DataFrame(data=superbase)\n",
        "    df_superbase.to_pickle(os.path.join(path_dist,'superbase.pkl'))\n",
        "    print('База данных создана. Путь к файлу: {}'.format(os.path.join(path_dist,'superbase.pkl')))\n",
        "  \n",
        "\n",
        "  def xcorr(self, x, y, normed=True, detrend=mlab.detrend_none, maxlags=1023):\n",
        "    Nx = len(x)\n",
        "    if Nx != len(y):\n",
        "        raise ValueError('x and y must be equal length')\n",
        "    x = detrend(np.asarray(x))\n",
        "    y = detrend(np.asarray(y))\n",
        "    correls = np.correlate(x, y, mode = 2)\n",
        "    if normed: correls /= np.sqrt(np.dot(x, x) * np.dot(y, y))\n",
        "    if maxlags is None: maxlags = Nx - 1\n",
        "    if maxlags >= Nx or maxlags < 1: raise ValueError('maxlags must be None or strictly ''positive < %d' % Nx)\n",
        "    lags = np.arange(-maxlags, maxlags + 1)\n",
        "    correls = correls[Nx - 1 - maxlags: Nx + maxlags]\n",
        "    return lags, correls\n",
        "\n",
        "  def func_cross_time_delay(self, list_of_sens, path_folder, path_dist, maxlags=None):\n",
        "    df_sp = pd.read_pickle(r'{}'.format(os.path.join(path_folder,'superbase.pkl')))\n",
        "    print('Считаем кросс-корреляцию')\n",
        "    print(f'Выбраны следующие пары сенсоров{list_of_sens}')\n",
        "    for k in list_of_sens:\n",
        "        s = [int(d) for d in k]\n",
        "        k = s[0]\n",
        "        n = s[1]\n",
        "        level_one={}\n",
        "        for i in range(len(df_sp)):\n",
        "            try:\n",
        "                x = df_sp.iloc[i][k]\n",
        "                y = df_sp.iloc[i][n]\n",
        "                if maxlags == None:\n",
        "                    maxlags = len(x) - 1\n",
        "                else:\n",
        "                    maxlags = int(maxlags)\n",
        "                z, a = self.xcorr(x, y, maxlags=maxlags)\n",
        "                cv = (np.array([z, a]))\n",
        "                t = np.argmax((cv[1][:]))\n",
        "                timedelay = cv[0][t]\n",
        "                level_one.update({i: [df_sp.iloc[i][0], timedelay,\n",
        "                                      np.array(a)]})  # убран последний столбец так как малоинформативен\n",
        "                # level_one.update({i: [df_sp.iloc[i][0], timedelay, np.array(a), np.array(z)]})\n",
        "            except:\n",
        "                pass  # есть строки где пустые поля поэтому просто игнорируем их\n",
        "        df_level_one = pd.DataFrame(level_one)\n",
        "        df_level_one = df_level_one.transpose()\n",
        "        df_level_one.to_pickle((os.path.join(path_dist, 'df_' + str(k) + str(n) + '.pkl')))\n",
        "        print(\"Файл готов: \" + f\"{os.path.join(path_dist, 'df_' + str(k) + str(n) + '.pkl')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-qyFHKL2DXB"
      },
      "source": [
        "txt_list = [file for file in glob.glob(os.path.join(path_anul, '*HFP[0-9].txt'))]\n",
        "txt_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4nZpQDnaym8"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import BoundaryNorm\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "path = path_end = r'path'\n",
        "\n",
        "file_list = [filename for filename in glob.glob(os.path.join(path, '*.txt'))]\n",
        "max_value = 2**15\n",
        "#k = file_list[0] \n",
        "filek = open(file_list[0])\n",
        "elem = len(filek.readlines())\n",
        "filek.close()\n",
        "t=0\n",
        "for k in file_list:\n",
        "    print(f'Считываем файл целиком {k}')\n",
        "    with open(k,'r') as file:\n",
        "        file_read = file.readlines()\n",
        "    z=0\n",
        "    slovar_spectr={}\n",
        "    print('Собираем файл по глубинам, производим STFT Kaiser')\n",
        "    while z < elem:\n",
        "        if len(file_read[z])>100:\n",
        "            mass_one = file_read[z].split(' ')\n",
        "            mass_one_np = np.array([int(k) for k in mass_one[1:]])\n",
        "            deep = mass_one[0]\n",
        "            fft_kaiser= np.fft.rfft(mass_one_np*np.kaiser(len(mass_one_np), 8))\n",
        "            if deep not in slovar_spectr:\n",
        "                slovar_spectr.update({deep: fft_kaiser})\n",
        "            if deep in slovar_spectr:\n",
        "                b = slovar_spectr[deep]\n",
        "                b = np.vstack((b, fft_kaiser))\n",
        "                slovar_spectr.update({deep:b})\n",
        "        z+=1\n",
        "    file_read= 0\n",
        "    \n",
        "    for k, v in slovar_spectr.items():\n",
        "        slovar_spectr.update({k: np.median(v, axis = 0)})\n",
        "    print('Пересчитываем в логарифмический масштаб')\n",
        "    for k, v in slovar_spectr.items():\n",
        "        slovar_spectr.update({k: 20*np.log10(v/(2**15))})\n",
        "    print('Строиться спектрограмма')\n",
        "    \n",
        "    z = np.array([abs(k) for k in slovar_spectr.values()])\n",
        "    y = (np.array([sorted([float(k) for k in list(slovar_spectr.keys())], reverse=True)] * 512)).transpose()\n",
        "    x = np.array([[k for k in range(0,512)]] * len(y))\n",
        "    print(len(x), len(x[0]), len(y), len(y[0]), len)\n",
        "    \n",
        "    z = z[:-1, :-1]\n",
        "    levels = MaxNLocator(nbins=500).tick_values(z.min(), z.max())\n",
        "    cmap = plt.get_cmap('Spectral_r', 100)\n",
        "    norm = BoundaryNorm(levels, ncolors=cmap.N, clip=True)\n",
        "    \n",
        "    fig, ax0 = plt.subplots(figsize=(10, 10))\n",
        "    im = ax0.pcolormesh(x, y, z, cmap=cmap, norm=norm)\n",
        "    fig.colorbar(im, ax=ax0)\n",
        "    ax0.set_title('Spectrogram')\n",
        "    ax0.set_xlabel('Frequency, kHz', fontsize=20)\n",
        "    ax0.set_ylabel('Deep, m', fontsize=20)\n",
        "    save_fig = os.path.join(path_end,'spectrogram'+str(t) + '.png')\n",
        "    print(save_fig)\n",
        "    plt.savefig(save_fig)\n",
        "    plt.close()\n",
        "    x=y=z=v=0\n",
        "    t+=1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}